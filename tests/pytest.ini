[tool:pytest]
# Pytest configuration for FPL ML System comprehensive testing
# Target: 90%+ coverage with research benchmark validation

# Test discovery patterns
python_files = test_*.py *_test.py
python_classes = Test* *Test *Tests
python_functions = test_*

# Test directories
testpaths = tests/

# Minimum coverage requirements (90% as per PRP)
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --cov=src
    --cov-report=html:tests/reports/coverage_report.html
    --cov-report=term-missing
    --cov-report=xml:tests/reports/coverage.xml
    --cov-fail-under=90
    --durations=10
    --maxfail=5
    -ra

# Parallel execution for faster test runs
# Uncomment when pytest-xdist is installed: -n auto

# Custom markers for test categorization
markers =
    unit: Unit tests for individual components and functions
    integration: Integration tests for component interaction and data flow
    e2e: End-to-end tests for complete workflows and user scenarios
    ml: Machine learning model tests and algorithm validation
    performance: Performance benchmarks and optimization speed tests
    slow: Slow-running tests (>30 seconds) - run separately in CI
    benchmark: Research benchmark validation tests (MSE < 0.003, etc.)
    api: API integration tests with FPL endpoints
    agent: PydanticAI agent tests using TestModel patterns
    load: Load testing and stress testing scenarios
    
    # Specific component markers
    config: Configuration and settings tests
    data: Data pipeline and processing tests
    models: Model validation and prediction tests
    cli: Command-line interface tests
    dashboard: Streamlit dashboard tests
    
    # Quality markers
    smoke: Quick smoke tests for basic functionality
    regression: Regression tests for bug prevention
    security: Security and validation tests

# Test timeout settings
timeout = 300
timeout_method = thread

# Async test configuration
asyncio_mode = auto

# Logging configuration for tests
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Filter warnings
filterwarnings =
    ignore::UserWarning:sklearn.*
    ignore::FutureWarning:pandas.*
    ignore::DeprecationWarning:numpy.*
    ignore::PendingDeprecationWarning
    error::pytest.PytestConfigWarning
    
# Pytest plugins
required_plugins = 
    pytest-cov>=4.0.0
    pytest-asyncio>=0.21.0
    pytest-mock>=3.10.0
    pytest-timeout>=2.1.0

# Environment variables for testing
env =
    ENVIRONMENT = test
    LOG_LEVEL = DEBUG
    DATABASE_URL = sqlite:///:memory:
    FPL_TEAM_ID = 12345
    OPENAI_API_KEY = test-key-12345
    DISABLE_EXTERNAL_APIS = true

# Coverage configuration
[coverage:run]
source = src/
omit = 
    */tests/*
    */venv/*
    */migrations/*
    */__pycache__/*
    */node_modules/*
    setup.py
    conftest.py

[coverage:report]
# Fail if coverage is below 90%
fail_under = 90
show_missing = true
skip_covered = false
precision = 2

# Exclude patterns from coverage
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

[coverage:html]
directory = tests/reports/coverage_report
title = FPL ML System Test Coverage Report

[coverage:xml]
output = tests/reports/coverage.xml